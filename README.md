# ğŸ§  DocMind â€” AI-Powered Document Analyzer

> Upload any PDF and have a conversation with it using AI. Get instant, accurate answers grounded strictly in your document.

![DocMind Screenshot](docmind_ss.jpeg)

---

## ğŸš€ Live Demo

> Upload a PDF â†’ Ask anything â†’ Get AI-powered answers with source citations

---

## ğŸ“Œ Overview

DocMind is a full-stack **RAG (Retrieval Augmented Generation)** application that allows users to upload PDF documents and ask natural language questions about them. Unlike general-purpose chatbots, DocMind answers **strictly from your uploaded document** â€” no hallucinations, no guessing.

Built as a showcase of combining **AI/ML engineering** with **modern frontend development**.

---

## âœ¨ Features

- ğŸ“„ **PDF Upload** â€” Drag & drop or click to upload any PDF (up to 10MB)
- ğŸ¤– **AI-Powered Q&A** â€” Ask questions in plain English, get accurate answers
- ğŸ” **Source Citations** â€” See exactly which chunks of the document the answer came from
- ğŸ’¬ **Chat History** â€” Follow-up questions work with full conversation context
- ğŸ“š **Multi-Document Support** â€” Upload multiple PDFs and query across all of them
- âš¡ **Real-time Responses** â€” Fast answers powered by Llama 3.1 via Groq

---

## ğŸ—ï¸ Architecture

```
User uploads PDF
      â†“
FastAPI receives file
      â†“
PyPDF2 extracts text
      â†“
LangChain splits text into chunks (1000 chars, 200 overlap)
      â†“
sentence-transformers converts chunks â†’ vectors (runs locally)
      â†“
FAISS stores vectors in memory

â”€â”€â”€ User asks a question â”€â”€â”€
      â†“
Question â†’ converted to vector
      â†“
FAISS finds top-4 most similar chunks (cosine similarity)
      â†“
Chunks + Question sent to Llama 3.1 (Groq) as context
      â†“
LLM generates grounded answer
      â†“
Answer + source chunks returned to Angular UI
```

---

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Purpose |
|-----------|---------|
| Python 3.13 | Core language |
| FastAPI | REST API framework |
| LangChain | RAG pipeline orchestration |
| FAISS | Vector similarity search |
| sentence-transformers | Local text embeddings (all-MiniLM-L6-v2) |
| Groq API (Llama 3.1) | LLM for answer generation |
| PyPDF2 | PDF text extraction |

### Frontend
| Technology | Purpose |
|-----------|---------|
| Angular 17 | Frontend framework (standalone components) |
| Tailwind CSS | Utility-first styling |
| TypeScript | Type-safe development |
| Angular HttpClient | API communication |

---


---

## âš™ï¸ Setup & Installation

### Prerequisites
- Python 3.9+
- Node.js 18+
- Free Groq API Key â†’ [console.groq.com](https://console.groq.com)

### Backend

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate        # Mac/Linux
venv\Scripts\activate           # Windows

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Add your GROQ_API_KEY inside .env

# Start server
python main.py
# Runs at http://localhost:8000
# Swagger docs at http://localhost:8000/docs
```

### Frontend

```bash
cd frontend

npm install
npm start
# Runs at http://localhost:4200
```

---

## ğŸ”‘ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check |
| GET | `/health` | Status + loaded documents |
| POST | `/upload` | Upload & process a PDF |
| POST | `/query` | Ask a question |
| GET | `/documents` | List uploaded documents |
| DELETE | `/reset` | Clear all documents + history |

---

## ğŸ§  Key ML/AI Concepts Used

**RAG (Retrieval Augmented Generation)**
Grounds LLM answers in real document content, preventing hallucinations. The model can only answer from what's in your PDF.

**Vector Embeddings**
Text is converted to high-dimensional vectors using `sentence-transformers/all-MiniLM-L6-v2`. Similar text produces similar vectors, enabling semantic (meaning-based) search.

**FAISS Vector Search**
Facebook AI Similarity Search â€” finds the most semantically relevant document chunks for any given question using cosine similarity in milliseconds.

**Text Chunking with Overlap**
PDFs are split into 1000-character chunks with 200-character overlap. The overlap ensures no important information is lost at chunk boundaries.

---


---

## ğŸ‘¨â€ğŸ’» Author

Built as a portfolio project to demonstrate full-stack AI application development â€” combining RAG pipeline engineering with modern Angular frontend development.

---

